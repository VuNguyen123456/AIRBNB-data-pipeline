# Airbnb End-to-End Data Engineering Pipeline

A production-grade data pipeline implementing medallion architecture (Bronze â†’ Silver â†’ Gold) with dimensional modeling, built using AWS S3, Snowflake, and dbt.

![Pipeline Architecture](https://img.shields.io/badge/AWS-S3-orange) ![Snowflake](https://img.shields.io/badge/Snowflake-Data_Warehouse-blue) ![dbt](https://img.shields.io/badge/dbt-Transform-red) ![Python](https://img.shields.io/badge/Python-3.12-green)

---

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Architecture](#architecture)
- [Technologies Used](#technologies-used)
- [Data Flow](#data-flow)
- [Key Features](#key-features)
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [Running the Pipeline](#running-the-pipeline)
- [Data Models](#data-models)
- [Testing](#testing)
- [Security](#security)
- [Learning Outcomes](#learning-outcomes)

---

## ğŸ¯ Project Overview

This project demonstrates a complete data engineering workflow for processing Airbnb booking data. It transforms raw CSV files from AWS S3 through multiple transformation layers in Snowflake using dbt, ultimately creating both a denormalized One Big Table (OBT) and an optimized Star Schema for analytics.

**Dataset:**
- 500 listings across multiple cities
- 200 hosts with performance metrics
- 5,000+ booking transactions

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AWS S3    â”‚  Raw CSV files (listings.csv, hosts.csv, bookings.csv)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SNOWFLAKE                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  STAGING SCHEMA (Raw Landing Zone)              â”‚   â”‚
â”‚  â”‚  - listings, bookings, hosts                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â”‚                                     â”‚
â”‚                   â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  BRONZE LAYER (Raw with Incremental Loading)    â”‚   â”‚
â”‚  â”‚  - bronze_listings                              â”‚   â”‚
â”‚  â”‚  - bronze_bookings                              â”‚   â”‚
â”‚  â”‚  - bronze_hosts                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â”‚                                     â”‚
â”‚                   â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  SILVER LAYER (Cleaned & Business Logic)        â”‚   â”‚
â”‚  â”‚  - silver_listings (price tagging)              â”‚   â”‚
â”‚  â”‚  - silver_bookings (calculated amounts)         â”‚   â”‚
â”‚  â”‚  - silver_hosts (response rate quality tiers)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                   â”‚                                     â”‚
â”‚                   â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  GOLD LAYER (Analytics-Ready)                   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  One Big Table (OBT)                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - Metadata-driven pipeline              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - Denormalized for easy querying        â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  Star Schema (Dimensional Model)         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - fact_bookings                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - dim_listings (SCD Type 2)             â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - dim_hosts (SCD Type 2)                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  - dim_bookings (SCD Type 2)             â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Technologies Used

| Technology | Purpose |
|------------|---------|
| **AWS S3** | Object storage for raw CSV files |
| **Snowflake** | Cloud data warehouse for data storage and compute |
| **dbt (Data Build Tool)** | SQL-based transformation framework |
| **Jinja** | Templating language for dynamic SQL generation |
| **Python** | Package management and environment setup |
| **Git/GitHub** | Version control and collaboration |
| **SQL** | Data transformation and querying |

---

## ğŸ”„ Data Flow

### Medallion Architecture

**Bronze Layer (Raw)**
- Direct copy from staging with incremental loading
- Preserves source data exactly as-is
- Serves as single source of truth
- Uses `created_at` timestamp for incremental updates

**Silver Layer (Cleaned)**
- Data cleaning and standardization
- Business logic application
- Derived columns and calculations
- Example transformations:
  - Response rate quality categorization (VERY_GOOD, GOOD, FAIR, POOR)
  - Price tier tagging (low, mid, high)
  - Total booking amount calculations

**Gold Layer (Analytics-Ready)**
- **One Big Table (OBT):** Metadata-driven denormalized table for easy analytics
- **Star Schema:** Optimized dimensional model with fact and dimension tables
- Slowly Changing Dimensions (SCD Type 2) for historical tracking

---

## âš¡ Key Features

### 1. **Incremental Loading**
- Reduces compute costs by processing only new records
- Based on `created_at` timestamp comparison
- Saves 80%+ in processing time for large datasets

### 2. **Metadata-Driven Pipeline**
- Configuration-based SQL generation using Jinja
- Add new tables by updating config array - no SQL changes needed
- Highly maintainable and scalable approach

```sql
{% set configs = [
    {"table": "...", "columns": "...", "join_condition": "..."},
    {"table": "...", "columns": "...", "join_condition": "..."}
] %}
```

### 3. **Slowly Changing Dimensions (SCD Type 2)**
- Tracks historical changes in dimension tables
- Preserves full audit trail with `dbt_valid_from` and `dbt_valid_to`
- Enables time-travel analytics

### 4. **Custom Jinja Macros**
- Reusable SQL functions for common operations
- Examples: `multiply()`, `tag()`, `trimmer()`
- Promotes DRY (Don't Repeat Yourself) principles

### 5. **Data Quality Testing**
- Custom SQL tests for business logic validation
- Built-in tests for uniqueness and null checks
- Warning severity for non-critical issues

### 6. **Ephemeral Models**
- Intermediate transformations without physical tables
- Reduces database clutter and storage costs
- Used for dimension staging before snapshots

---

## ğŸ“ Project Structure

```
aws_dbt_snowflake_project/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sources/
â”‚   â”‚   â””â”€â”€ sources.yml              # Source table definitions
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ bronze_bookings.sql      # Raw bookings (incremental)
â”‚   â”‚   â”œâ”€â”€ bronze_hosts.sql         # Raw hosts (incremental)
â”‚   â”‚   â””â”€â”€ bronze_listings.sql      # Raw listings (incremental)
â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”œâ”€â”€ silver_bookings.sql      # Cleaned bookings
â”‚   â”‚   â”œâ”€â”€ silver_hosts.sql         # Cleaned hosts with quality tiers
â”‚   â”‚   â””â”€â”€ silver_listings.sql      # Cleaned listings with price tags
â”‚   â”œâ”€â”€ gold/
â”‚   â”‚   â”œâ”€â”€ obt.sql                  # One Big Table (metadata-driven)
â”‚   â”‚   â”œâ”€â”€ fact_bookings.sql        # Fact table (metrics only)
â”‚   â”‚   â””â”€â”€ ephemeral/
â”‚   â”‚       â”œâ”€â”€ bookings.sql         # Dimension staging (ephemeral)
â”‚   â”‚       â”œâ”€â”€ hosts.sql            # Dimension staging (ephemeral)
â”‚   â”‚       â””â”€â”€ listings.sql         # Dimension staging (ephemeral)
â”‚   â””â”€â”€ properties.yml               # Model configurations
â”œâ”€â”€ macros/
â”‚   â”œâ”€â”€ multiply.sql                 # Custom multiplication macro
â”‚   â”œâ”€â”€ tag.sql                      # Price tagging macro
â”‚   â””â”€â”€ trimmer.sql                  # String cleaning macro
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ booking_amount_check.sql     # Data quality test
â”œâ”€â”€ snapshots/
â”‚   â”œâ”€â”€ dim_bookings.yml             # Booking dimension (SCD Type 2)
â”‚   â”œâ”€â”€ dim_hosts.yml                # Host dimension (SCD Type 2)
â”‚   â””â”€â”€ dim_listings.yml             # Listing dimension (SCD Type 2)
â”œâ”€â”€ dbt_project.yml                  # Project configuration
â”œâ”€â”€ profiles.yml                     # Snowflake credentials (gitignored)
â”œâ”€â”€ .gitignore                       # Security - excludes credentials
â””â”€â”€ README.md                        # This file
```

---

## ğŸš€ Setup Instructions

### Prerequisites

- Python 3.12+
- AWS account with S3 access
- Snowflake account (free trial available)
- Git

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/airbnb-data-pipeline.git
cd airbnb-data-pipeline
```

### 2. Set Up Python Environment

```bash
# Create virtual environment
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# Activate (Mac/Linux)
source .venv/bin/activate

# Install dependencies
pip install dbt-core dbt-snowflake
```

### 3. Configure Snowflake Connection

Create `profiles.yml` in the project root:

```yaml
aws_dbt_snowflake_project:
  outputs:
    dev:
      account: YOUR_ACCOUNT_IDENTIFIER
      database: AIRBNB
      password: YOUR_PASSWORD
      role: ACCOUNTADMIN
      schema: dbt_schema
      threads: 1
      type: snowflake
      user: YOUR_USERNAME
      warehouse: COMPUTE_WH
  target: dev
```

**âš ï¸ IMPORTANT:** Never commit `profiles.yml` to version control!

### 4. Set Up AWS S3

```bash
# Upload CSV files to S3
aws s3 cp listings.csv s3://your-bucket-name/src/
aws s3 cp hosts.csv s3://your-bucket-name/src/
aws s3 cp bookings.csv s3://your-bucket-name/src/
```

### 5. Load Data to Snowflake Staging

```sql
-- In Snowflake, create database and schema
CREATE DATABASE AIRBNB;
CREATE SCHEMA staging;

-- Create tables and load from S3 using COPY INTO
-- (See ddl.sql for full schema definitions)
```

---

## â–¶ï¸ Running the Pipeline

### Build All Models

```bash
# Run all transformations
dbt run
```

### Build Specific Layers

```bash
# Bronze layer only
dbt run --select bronze

# Silver layer only
dbt run --select silver

# Gold layer only
dbt run --select gold
```

### Full Refresh (Reload All Data)

```bash
dbt run --full-refresh
```

### Run Snapshots (SCD Type 2)

```bash
dbt snapshot
```

### Run Tests

```bash
# Run all tests
dbt test

# Run specific test
dbt test --select booking_amount_check
```

### Build Everything (Models + Snapshots + Tests)

```bash
dbt build
```

---

## ğŸ“Š Data Models

### Bronze Layer

**Purpose:** Raw data preservation with incremental loading

**Models:**
- `bronze_bookings` - 5,000 booking records
- `bronze_hosts` - 200 host profiles
- `bronze_listings` - 500 property listings

**Key Feature:** Incremental materialization using `created_at` timestamp

### Silver Layer

**Purpose:** Data cleaning and business logic

**Transformations:**

| Model | Transformation Examples |
|-------|------------------------|
| `silver_bookings` | Calculate total booking amount with custom `multiply()` macro |
| `silver_hosts` | Categorize response rates (VERY_GOOD, GOOD, FAIR, POOR) |
| `silver_listings` | Tag prices as low/mid/high using `tag()` macro |

### Gold Layer - One Big Table (OBT)

**Purpose:** Denormalized table for easy analytics

**Features:**
- Metadata-driven SQL generation
- All entities joined in one wide table
- Optimized for BI tools (Tableau, Power BI)
- Easy for non-technical users to query

### Gold Layer - Star Schema

**Fact Table:** `fact_bookings`
- Booking metrics (amounts, fees, nights)
- Foreign keys to dimensions
- Optimized for aggregation queries

**Dimension Tables (SCD Type 2):**
- `dim_bookings` - Booking status and dates
- `dim_hosts` - Host information with history
- `dim_listings` - Property details with history

**Historical Tracking:**
```sql
-- Query historical state
SELECT *
FROM dim_hosts
WHERE host_id = 123
  AND '2024-06-15' BETWEEN dbt_valid_from AND dbt_valid_to
```

---

## ğŸ§ª Testing

### Custom SQL Test Example

```sql
-- tests/booking_amount_check.sql
{{ config(severity = 'warn') }}

SELECT *
FROM {{ source('staging', 'bookings') }}
WHERE BOOKING_AMOUNT < 200
```

**Test Logic:**
- Returns 0 rows = âœ… PASS
- Returns rows = âš ï¸ WARNING (flags suspicious bookings)

### Built-in Tests (in schema.yml)

```yaml
models:
  - name: bronze_bookings
    columns:
      - name: booking_id
        tests:
          - unique
          - not_null
```

---

## ğŸ”’ Security

This project follows security best practices:

âœ… **Credentials Protection**
- `profiles.yml` excluded via `.gitignore`
- No hardcoded passwords or API keys in SQL files
- AWS credentials managed separately

âœ… **What's Safe to Share**
- dbt models and transformations
- Project configuration (dbt_project.yml)
- Tests and macros
- Documentation

âŒ **Never Committed**
- `profiles.yml` (Snowflake credentials)
- `.venv/` (Python environment)
- `target/` (Compiled SQL)
- AWS access keys

---

## ğŸ“š Learning Outcomes

### Technical Skills Demonstrated

**Data Engineering Concepts:**
- âœ… Medallion architecture (Bronze/Silver/Gold)
- âœ… Dimensional modeling (Star Schema)
- âœ… Slowly Changing Dimensions (SCD Type 2)
- âœ… Incremental data loading
- âœ… Data quality testing

**dbt Expertise:**
- âœ… Declarative transformations
- âœ… Jinja templating for dynamic SQL
- âœ… Custom macros for reusable logic
- âœ… Ephemeral models
- âœ… Snapshot functionality
- âœ… Source and model referencing

**Best Practices:**
- âœ… Version control with Git
- âœ… Credential management and security
- âœ… Code modularity and reusability
- âœ… Documentation
- âœ… Metadata-driven design patterns

---

## ğŸ¤ Interview Talking Points

**"Tell me about a data pipeline you built"**

> "I built an end-to-end data pipeline following medallion architecture. Starting with raw CSV files in AWS S3, I loaded data into Snowflake and used dbt to transform it through Bronze, Silver, and Gold layers. The Bronze layer preserves raw data with incremental loading to reduce costs by 80%. Silver applies business logic like categorizing host response rates. Gold creates both a metadata-driven One Big Table for easy analytics and a Star Schema with SCD Type 2 for historical tracking. I implemented custom Jinja macros for reusable logic and data quality tests to ensure pipeline reliability."

**Key Metrics:**
- 5,700+ records processed
- 3 transformation layers
- 80%+ cost reduction via incremental loading
- SCD Type 2 historical tracking
- Metadata-driven scalability

---

## ğŸ“ License

This project is open source and available for educational purposes.

---

## ğŸ¤ Contributing

This is a learning project, but feedback and suggestions are welcome! Feel free to open an issue or submit a pull request.


---

**Built with â¤ï¸ using AWS, Snowflake, and dbt**
